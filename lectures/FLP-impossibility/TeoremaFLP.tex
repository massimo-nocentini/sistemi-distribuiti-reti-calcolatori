\documentclass{article}
\usepackage[utf8x]{inputenc} % codifica scrittura
\usepackage[nochapters]{classicthesis} % nochapters
\usepackage[italian]{babel}
%\usepackage{inputenc}
\usepackage[T1]{fontenc} 
\usepackage[square,numbers]{natbib} 
\usepackage{amsmath, amsthm,tikz}
\usetikzlibrary{snakes}
\newtheorem{definizione}{Definizione}  
\newtheorem{lemma}{Lemma}
\newtheorem{teorema}{Teorema}  
\newtheorem{proprieta}{Proprietà}  
\begin{document}

\title{\rmfamily\normalfont\spacedallcaps{Risultato FLP}}
\author{\spacedlowsmallcaps{Chiara Pierucci}\\
	\spacedlowsmallcaps{Massimo Nocentini}\\
	\spacedlowsmallcaps{Valentino Bruni}}
\date{} % no date

\maketitle


\begin{abstract}
  In questo lavoro ci proponiamo di studiare il risultato di
  impossilit\`a del consenso in un sistema totalmente asincrono,
  dimostrato da Fischer, Lynch e Paterson nel 1985.

  Nella nostra esposizione intendiamo riportare i principali risultati
  raggiunti dagli autori, integrando alcuni dettagli con brevi
  interventi che abbiamo sviluppato durante lo studio.

  Questo nostro elaborato \`e diviso in due macro sezioni: la prima ha
  un taglio pi\`u teorico e tratta la prova d'impossibilit\`a; la
  seconda, invece, ha un taglio pi\`u implementativo e propone uno
  schema per risolvere il problema del consenso, aggiungendo alcune
  ipotesi.
\end{abstract}
       
\tableofcontents

\section{Introduzione}
\label{sec:intro}
Prima di mostrare il risultato principale, cerchiamo di descrivere
l'ambiente in cui andiamo a lavorare, identificando i concetti
fondamentali che saranno oggetto di discussione.\\\\
Immaginiamo che un insieme finito di processori debba collaborare con
lo scopo di raggiungere una decisione comune. Per raggiungere questo
obiettivo hanno la possibilit\`a di scambiarsi un numero finito di
messaggi ed eseguire una computazione locale (di cui non ci interessa
limitare la complessit\`a). Lo scambio di messaggi segue uno schema
\emph{asincrono} di cui riportiamo, per chiarezza, le propriet\`a:
\begin{description}
\item[consegna] se un messaggio $m$ \`e stato inviato ad un processore
  $p$, prima o poi $p$ ricever\`a $m$ una e una sola volta;
\item[ritardo] un processore $p$ non pu\`o fare assunzioni sugli
  istanti di tempo in cui ricever\`a i messaggi a lui destinati;
\item[ordine] i messaggi destinati ad un processore $p$ possono non
  essere consegnati nell'ordine in cui sono stati inviati;
\end{description}

Nei sistemi che tratteremo si contempla la possibilit\`a che alcuni
processori possano subire un guasto di natura ``stop'', cessando di
scambiare messaggi e eseguire una computazione locale, escludendo
invece guasti di tipo bizantino.

Inoltre, dalle propriet\`a sopra elencate, non \`e possibile rilevare
possibili guasti in quanto un processore $p$ non \`e in grado di
discriminare un processore guasto da un processore che semplicemente
ha bisogno di molto tempo per eseguire la propria computazione. Di
conseguenza nessuno di essi pu\`o escludere a priori gli altri per
prendere la propria decisione.

\section{Risultato di impossibilit\`a FLP}

Le idee introdotte nei paragrafi precedenti possono essere
formalizzate con le seguenti definizioni, nelle quali siamo
volutamente concisi e le abbiamo scritte immaginando i processori come
semplici macchine di Turing:

\begin{definizione}[Protocollo di consenso]
  Un protocollo di consenso $P$ è un sistema asincrono composto da $n$
  processori, con $n\geq2$. Ogni processore $P$ possiede un registro
  di input binario $x_p$, un registro di output $y_p$ con valori in
  $\{b,0,1\}$ e una memoria interna che si suppone infinita.
\end{definizione}

\begin{definizione}[Stato interno di un processore]
  Lo stato interno di un processore è costituito dal valore dei
  registri di input e di output e dal contenuto della memoria.  Diremo
  che un processore $p$ si trova in uno stato di decisione se $y_p \in
  \lbrace 0,1 \rbrace$. 
\end{definizione}

Sottolineiamo che una volta raggiunto uno stato di decisione, un
processore $p$ non pu\`o pi\`u modificare il valore $y_p$.

\subsection{Astrazione del sistema asincrono}

In questa sezione sviluppiamo le astrazioni necessarie per catturare i
concetti e le propriet\`a del sistema asincrono che abbiamo descritto
in Sezione \ref{sec:intro}.

\begin{definizione}[Messaggio]
  Un messaggio è una coppia $(p,m)$ dove $p$ è il processo
  destinatario e $m$ è il contenuto da recapitare a $p$.
\end{definizione}

Per formalizzare il ritardo arbitrario e il non ordine di ricezione
dei messaggi, introduciamo l'entit\`a \emph{message buffer}, unico
meccanismo per lo scambio di messaggi. Il lettore deve dunque
immaginare che due processi non possono comunicare ``direttamente'',
ma devono depositare i loro messaggi usando questa entit\`a.

\begin{definizione}[Message buffer]
  Un \emph{message buffer} \`e una struttura dati simile ad un
  insieme, contenente messaggi inviati ma non ancora ricevuti dai vari
  processori. Per garantire lo scambio di messaggi, un message buffer
  supporta le seguenti operazioni:
\begin{itemize}
\item \texttt{send$(p,m)$}: il messaggio $(p,m)$ è inserito nel buffer
  ed è pronto per essere recapitato;
\item \texttt{receive$(p)$}: un messaggio viene recapitato a $p$. Più
  precisamente, il message buffer decide se estrarre un messaggio
  $(p,m)$ e recapitare $m$ oppure inviare un messaggio speciale
  $\perp$ lasciando inalterato il suo contenuto.
\end{itemize}
\end{definizione}
La precedente definizione mette in risalto il non determinismo dello
scambio di messaggi. Infatti, se un processo $p$ invoca la primitiva
\texttt{receive(p)}, il message buffer può arbitrariamente decidere di
inviare al processo $p$ il contenuto speciale $\perp$ anche in
presenza di un messaggio $m$. La risposta $\perp$ permette di
rappresentare il ritardo arbitrario nella ricezione di un
messaggio. Per formalizzare la propriet\`a di consegna di ogni
messaggio ad un processo $p$, il message buffer, a seguito di infinite
\texttt{receive(p)}, può rispondere $\perp$ un numero \emph{finito} di
volte, non conosciuto a priori. Quindi, se un processore $p$ invoca la
primitiva \texttt{receive(p)} infinite volte, ha la garanzia di
riceve, prima o poi, \emph{tutti} i messaggi a lui destinati. Infine
il message buffer non garantisce di recapitare i messaggi nell'ordine
in cui sono stati depositati. Alla luce di queste osservazioni, diremo
che un processore $p$ si dice guasto se può effettuare solo un numero
finito di \texttt{receive(p)}.

\subsection{Grafo di esecuzione}

In questa sezione formalizziamo il concetto di esecuzione del
protocollo $P$, costruendo un grafo $G_P$ che ha per vertici le
\emph{configurazioni} e per archi gli \emph{step}. Diamo le
definizioni di quest'ultimi due concetti:

\begin{definizione}[Configurazione]
  Una \emph{configurazione} \`e costituita dall'insieme degli stati
  interni dei processori e dal contenuto del message buffer. Una
  configurazione si dice \emph{iniziale} quando il message buffer è
  vuoto e lo stato interno di ogni processore $p$ è tale che $y_p =
  b$.
\end{definizione}

\begin{definizione}[Step]
  Uno \emph{step} associa due configurazioni $C_1, C_2$ rispetto ad un
  processore $p$ e a un messaggio $m \in M\cup\{\perp\}$, e
  scriveremo $C_1 \xrightarrow{(p,m)} C_2$, se e solo
  se $p$:
  \begin{enumerate}
  \item esegue \texttt{receive($p$)} ottenendo $m$;
  \item in base al suo stato interno computa un nuovo stato e invia un
    insieme finito di messaggi agli altri processori, modificando
    quindi il contenuto del message buffer.
  \end{enumerate} 
  Il comportamento deterministico del processore è completamente
  determinato dalla coppia $e=(p,m)$ chiamata evento, con lieve abuso
  di notazione. Se $C_1 \xrightarrow{e} C_2$ allora indichiamo con
  $e(C_1)=C_2$ la configurazione raggiunta applicando l'evento $e$ a
  $C_1$.
\end{definizione}

Un cammino del grafo rappresenta una possibile esecuzione del
protocollo, pertanto definiamo il concetto di \emph{run}:

\begin{definizione}[Run]
  Un \emph{run} è una sequenza $\sigma$, finita o infinita, di eventi
  che può essere applicata ad una configurazione $C$; se $\sigma$ è
  finita indichiamo con $\sigma(C)$ la configurazione raggiunta
  eseguendo $\sigma$ a partire da $C$. Una configurazione si dice
  \emph{accessibile} se \`e raggiungibile da una configurazione
  iniziale.
\end{definizione}

Nel seguente lemma riportiamo un risultato generale che ci sar\`a
utile nelle prove successive. L'idea alla base \`e quella di
considerare due run in cui insiemi disgiunti di processori ricevono
messaggi: se applichiamo i due run ad una stessa configurazione,
arriveremo in due configurazioni distinte, in cui i messaggi destinati
ai processori non coinvolti nel run applicato saranno disponibili e,
quindi, possiamo scambiare l'applicazione dei run, raggiungendo la
stessa configurazione (Figura \ref{fig:concatenazioneSchedule}).

\begin{lemma}
  \label{lemma:eventsInterleaving}
  Sia $C$ una configurazione e siano $\sigma_1$, $\sigma_2$ due run
  che operano su insiemi di processori disgiunti. Allora
  $\sigma_2(\sigma_1(C))=\sigma_1(\sigma_2(C))$.
\end{lemma}

\begin{proof}
  Siano $P_1$ e $P_2$ gli insiemi dei processori coinvolti
  rispettivamente in $\sigma_1$ e $\sigma_2$. Sia $C_1=\sigma_1(C)$ e
  sia $C_2=\sigma_2(C)$. In $C_1$ solo i processori in $P_1$ avranno
  ricevuto messaggi e modificato il loro stato, così come succede per
  i processori in $P_2$. Dal punto di vista dei processori in $P_1$ le
  configurazioni $C$ e $C_2$ sono equivalenti e, per quelli in $P_2$
  sono equivalenti le configurazioni $C$ e $C_1$. Applicando
  $\sigma_2$ a $C_1$ si modifica lo stato interno dei soli processori
  in $P_2$ e, analogamente, applicando $\sigma_1$ a $C_2$ si altera lo
  stato interno dei soli processori in $P_1$. Dunque, dato il
  comportamento deterministico dei processori, vale
  $\sigma_2(C_1)=\sigma_1(C_2)=C'$.
\end{proof}

\begin{figure}[!h]
  \centering \input{img/concatenazioneSchedule.tex}\caption{Run
    disgiunti concatenati}\label{fig:concatenazioneSchedule}
\end{figure}

\subsection{Consenso e correttezza totale del protocollo}

Questa sezione prepara il lettore alla prova del teorema FLP,
precisando che cosa significa raggiungere il consenso, in ambiente
asincrono, per un insieme di processori. Nonostante nella realt\`a sia
richiesto che tutti i processori non guasti decidano lo stesso valore,
nel nostro studio ci siamo focalizzati sulla versione ``debole'' del
problema: ci interessa dimostrare che pur considerando un solo
processo guasto, esiste un run $\sigma$ in cui \emph{nessun}
processore \`e in grado di raggiungere una decisione univoca.

\begin{definizione}[Valore di decisione di una configurazione]
  Una configurazione $C$ si dice che \emph{ha valore di decisione} $v
  \in \{0,1\}$ se almeno un processore $p$ si trova in uno stato di
  decisione con $y_p=v$.
\end{definizione}

\begin{definizione}[Protocollo parzialmente corretto]
  Un protocollo di consenso $P$ si dice \emph{parzialmente corretto}
  se il grafo di esecuzione $G_P$ soddisfa le seguenti propriet\`a:
\begin{itemize}
\item nessuna configurazione accessibile ha più di un valore di
  decisione;
\item esiste una configurazione accessibile con valore di decisione
  $0$ e una con valore di decisione $1$.
\end{itemize}  
\end{definizione}

\begin{figure}[!h]
  \centering \input{img/parzialmenteCorretto.tex}\caption{Run
    parzialmente corretti}\label{fig:parzialmenteCorretto}
\end{figure}

In Figura \ref{fig:parzialmenteCorretto} riportiamo nelle etichette
delle configurazioni le sequenze dei contenuti dei registri di output:
osserviamo che dalla configurazione iniziale $C_i$ si raggiungono sia
configurazioni in cui un processore ha uno stato di decisione $0$ sia
configurazioni in cui un processore ha uno stato di decisione
$1$. Inoltre da queste configurazioni con valore di decisione \`e
possibile raggiungere altre configurazioni con uguale valore di
decisione.

\begin{definizione}[Run ammissibile]
  Un run $\sigma$ si dice \emph{ammissibile} se 
  \begin{itemize}
  \item per ogni configurazione $C$ raggiunta attraverso un evento
    $e\in \sigma$, $C$ contiene al più un processore guasto;
  \item esiste una configurazione $C$ raggiunta attraverso un evento
    $e\in \sigma$ tale che per ogni processore $p$ non guasto, tutti i
    messaggi contenuti nel message buffer in $C$ destinati a $p$ sono
    stati recapitati.
  \end{itemize}
\end{definizione}

\begin{definizione}[Run decisionale]
  Un run $\sigma$ si dice \emph{decisionale} se esiste una
  configurazione $C$ raggiunta attraverso un evento $e\in \sigma$ tale
  che almeno un processo raggiunge uno stato di decisione.
\end{definizione}

\begin{definizione}[Protocollo totalmente corretto a meno di un guasto]
  Un protocollo di consenso $P$ si dice \emph{totalmente corretto},
  nonostante la presenza di un guasto, se:
\begin{itemize}
\item  $P$ è parzialmente corretto;
\item per ogni run $\sigma$ ammissibile allora $\sigma$ \`e decisionale.
\end{itemize}
\end{definizione}

Nel seguito di questo documento ogni volta che useremo un run $\sigma$
si assume che $\sigma$ sia almeno ammissibile. Inoltre useremo
l'aggettivo ``concordi'' se due configurazioni hanno stesso valore di
decisione, ``discordi'' altrimenti.

\begin{teorema}
Non esistono protocolli di consenso totalmente corretti a meno di un guasto.
\end{teorema}

\begin{proof}
  L'idea alla base della prova è quella di procedere per assurdo,
  assumendo che esista un protocollo $P$ totalmente corretto a meno di
  un guasto: proveremo dei risultati intermedi per arrivare ad una
  contraddizione. La prova si articola in due fasi:
  \begin{enumerate}
  \item dimostrare l'esistenza di configurazioni iniziali da cui,
    usando due run distinte, è possibile raggiungere due
    configurazioni discordi;
  \item dimostrare l'esistenza di un run infinito tale che ogni
    configurazione attraversata non ha un valore di decisione.
  \end{enumerate}
  La prima fase assicura che esistono delle esecuzioni in cui la
  decisione non è predeterminata mentre la seconda assicura che esiste
  una esecuzione in cui ogni processo non decide nessun valore.  Nel
  seguito useremo tre propriet\`a per ``catalogare'' una
  configurazione:
  \begin{itemize}
  \item una configurazione $C$ si dice \emph{bivalente} se l'insieme
    dei valori di decisione delle configurazioni raggiungibili da $C$
    è $\{0,1\}$;
  \item una configurazione $C$ si dice ${i}$-\emph{valente} se
    l'insieme dei valori di decisione delle configurazioni
    raggiungibili da $C$ è $\{i\}$, con $i\in \lbrace 0, 1
    \rbrace$. Nel seguito diremo che una configurazione $C$ \`e
    \emph{monovalente} se \`e o $0$-valente o $1$-valente, ma non
    bivalente.
  \end{itemize}

  Osserviamo che l'insieme dei valori di decisione non può essere
  vuoto in quanto, dato che il protocollo $P$ è supposto totalmente
  corretto per ipotesi di assurdo, segue che il grafo di esecuzione
  contiene solo run decisionali, ovvero ogni run conterrà una
  configurazione con un valore di decisione.

\begin{lemma}
\label{lemma:bivalentInitialConfigurationExists}
Il protocollo $P$ possiede una configurazione iniziale bivalente.
\end{lemma}

\begin{proof}
  Per assurdo, assumiamo che non esista alcuna configurazione iniziale
  bivalente. Dunque, tutte le configurazioni iniziali del grafo di
  esecuzione di $P$ devono essere o $1$-valenti o
  $0$-valenti. Costruiamo un ordinamento su di esse usando il seguente
  criterio: una configurazione $C_1$ precede $C_2$ se e solo se i
  valori iniziali dei processori sono gli stessi a meno di esattamente
  un processore $p$ e $x_p^{(C_1)} < x_p^{(C_2)}$, dove abbiamo
  indicato con $x_p^{(C_i)}$ il valore del registro $x_p$ nella
  configurazione $C_i$. Usando tale ordinamento, dimostriamo che ne
  esistono due consecutive tali che una risulta $0$-valente e l'altra
  $1$-valente. Per mostrare ciò supponiamo che, senza perdita di
  generalità, tutte le configurazioni ordinate siano
  $0$-valenti. Tuttavia tale assunzione non rispetta la propriet\`a di
  parziale correttezza del protocollo $P$, in particolare deve
  esistere una configurazione con valore di decisione $1$
  raggiungibile da una iniziale. Sia questa configurazione iniziale
  $C_1$ e consideriamo una configurazione $C_0$ a lei consecutiva
  (quest'ultima esiste sempre per come abbiamo definito
  l'ordinamento). Dato che $C_0$ e $C_1$ sono consecutive, esse
  differiscono per un solo valore iniziale in corrispondenza di un
  processore $p$. Costruiamo un run decisionale $\sigma$ (non possiamo
  fare altrimenti poichè $P$ è supposto totalmente corretto) in cui il
  processore $p$ non è coinvolto, ovvero in cui $p$ non riceve
  messaggi. Applicando $\sigma$ a $C_0$ e a $C_1$ si raggiungono due
  configurazioni distinte in cui lo stato di ogni processo $p'$, tale
  che $p'\neq p$, è uguale in entrambe; l'unica differenza è il
  contenuto di $x_p$. Ma dato che $\sigma$ è un run decisionale solo
  due valori potranno essere decisi: se sarà deciso $0$ allora $C_1$ è
  bivalente, se verrà deciso $1$ allora $C_0$ è bivalente. In entrambi
  i casi abbiamo raggiunto una contraddizione in quanto sia $C_0$ che
  $C_1$ erano supposte non bivalenti.

% Figura matrice collezione di configurazioni
% commento relativo al fatto che sigma e dunque il contenuto del message buffer è fissato e deciso da noi. 

\end{proof}
 
\begin{lemma}
\label{lemma:oneStepFromConfigInCYieldConfigInD}
Sia $C$ una configurazione bivalente del protocollo $P$, e sia
$e=(p,m)$ un evento applicabile a $C$. Sia $\mathcal{C}$ l'insieme
delle configurazioni raggiungibili da $C$ attraverso dei run $\sigma$
tali che l'evento $e$ non appare in $\sigma$, e sia $\mathcal{D}$
l'insieme di tutte le configurazioni raggiungibili applicando $e$ ad
ogni configurazione presente in $\mathcal{C}$. Allora $\mathcal{D}$
contiene una configurazione bivalente.
\end{lemma}
Osserviamo che il processo $p$ può ricevere il messaggio in $C$ e
dunque, per definizione di $\mathcal{C}$, sarà possibile, per $p$,
ricevere $m$ anche in ogni configurazione in $\mathcal{C}$.
\begin{proof}
  Per assurdo assumiamo che $\mathcal{D}$ non contenga alcuna
  configurazione bivalente, dunque ogni configurazione in
  $\mathcal{D}$ è o $0$-valente o $1$-valente. Siano $E_0$ ed $E_1$ le
  configurazioni rispettivamente $0$-valente e $1$-valente
  raggiungibili da $C$ e analizziamo i seguenti due casi. Senza
  perdita di generalità, ci focalizzeremo sullo studio di $E_0$ dal
  momento che lo stesso ragionamento si può ripetere per $E_1$:
\begin{itemize}
\item $E_0 \in \mathcal{C}$ e dunque è possibile applicare l'evento
  $e$ alla configurazione $E_0$ ottenendo una configurazione $F_0 \in
  \mathcal{D}$. Infatti, applicare $e$ equivale a far ricevere il
  messaggio $m$ al processore $p$ e a raggiungere la configurazione
  $F_0 \in \mathcal{D}$. Per l'ipotesi di assurdo su $\mathcal{D}$,
  $F_0$ deve essere monovalente: non può essere $1$-valente in quanto
  contraddirebbe il valore di decisione di $E_0$ e quindi anch'essa
  risulta $0$-valente;
\item $E_0 \not \in \mathcal{C}$, dunque deve esistere una
  configurazione raggiungibile applicando $e$, ottenendo quindi una
  nuova configurazione $F_0' \in \mathcal{D}$ dalla quale è possibile
  raggiungere $E_0$. Dato che $F_0' \in \mathcal{D}$ allora $F_0'$ \`e
  monovalente, ma dato che raggiunger\`a $E_0$, che è $0$-valente,
  anche $F_0'$ deve esserlo per non violare la validità del
  protocollo.
\end{itemize}
Notiamo quindi che a prescindere dai due casi, $\mathcal{D}$ conterrà
una configurazione $0$-valente. Tuttavia, ripetendo un ragionamento
analogo per la configurazione $E_1$ si ottiene che $\mathcal{D}$ deve
contenere anche una configurazione $1$-valente.

Due configurazioni si dicono \emph{vicine} se una è raggiungibile
dall'altra con l'applicazione di esattamente uno step, ovvero
permettendo ad un processo $p$ di ricevere un messaggio $m$.

\begin{lemma}
  \label{lemma:neighborsConfigsYieldDiscordingConfigs}
  Esiste una coppia $C_{\alpha}, C_{\beta} \in \mathcal{C}$ di
  configurazioni vicine e siano $D_{\alpha} = e(C_{\alpha}), D_{\beta}
  = e (C_{\beta})\in \mathcal{D}$ tali che, senza perdita di
  generalit\`a, $D_{\alpha}$ \`e $0$-valente e $D_{\beta}$ \`e
  $1$-valente.
\end{lemma}
\begin{proof}
  Supponiamo, per assurdo, che ogni coppia di configurazioni vicine
  debba raggiungere lo stesso valore di decisione. Data l'esistenza di
  una configurazione iniziale bivalente, esisteranno due coppie di
  configurazioni vicine $(C_{\alpha}, C_{\beta})$ e $(C_{\gamma},
  C_{\eta})$ tali che $C_{\alpha}$ e $C_{\beta}$ sono, senza perdere
  di generalit\`a, $0$-valenti mentre $C_{\gamma}$ e $C_{\eta}$
  $1$-valenti. Ma dato che i run necessari per raggiungere ognuna di
  esse sono run ammissibili, supponiamo che in $C_{\alpha}$ esista un
  processo $q$ capace di invocare \texttt{receive(q)} infinite volte:
  nel momento in cui $q$ ha ricevuto tutti i messaggi a lui destinati,
  il message buffer restituir\`a il messaggio $(q, \perp)$ permettendo
  da $C_{\alpha}$ di raggiungere ogni altra configurazione, e quindi
  anche $C_{\gamma}$. Ma questo non \`e possibile in quanto
  $C_{\alpha}$ e $C_{\gamma}$ sarebbero vicine dalle quali si
  raggiungono configurazioni discordi.
\end{proof}


%FIGURA INDUZIONE

Per il Lemma \ref{lemma:neighborsConfigsYieldDiscordingConfigs}, sia
$C_{\alpha}, C_{\beta} \in \mathcal{C}$ una coppia di configurazioni
vicine, grazie all'evento $e'=(p',m')$, tali che, applicando l'evento
$e=(p,m)$, raggiungono rispettivamente le configurazioni $d_0$ e $d_1
\in \mathcal{D}$, tali che $d_{0}$ \`e $0$-valente e $d_{1}$ \`e
$1$-valente, senza perdit\`a di generalit\`a. Analizziamo quindi i
seguenti due casi:
\begin{itemize}
\item supponiamo che $p \neq p'$: per il Lemma
  \ref{lemma:eventsInterleaving}, possiamo applicare l'evento $e'$ a
  $d_0$ raggiungendo $d_1$, ovvero si riesce a passare da una
  configurazione $0$-valente ad una $1$-valente. Questo non \`e
  possibile in quanto si violerebbe la correttezza del protocollo;

\item supponiamo che $p=p'$. Allora esiste un run decisionale $\sigma$
  che non coinvolge $p$ e sia $A=\sigma(C_{\alpha})$. Tale run risulta
  applicabile, per il Lemma \ref{lemma:eventsInterleaving}, anche alle
  configurazioni $d_0$ e $d_1$ producendo rispettivamente $E_0$ e
  $E_1$ che, per la correttezza del protocollo, devono mantenere lo
  stesso valore di decisione di $d_0$ e di $d_1$. Osserviamo che nella
  configurazione $A$, $p$ è ancora in grado di ricevere messaggi ed,
  in particolare, si possono applicare sia l' evento $e$, sia la
  concatenazione di eventi $e \circ e'$. Risulta che $e(A)=E_0$ e che
  $e(e'(A))=E_1$, ovvero la configurazione $A$ è bivalente,
  contraddicendo l'ipotesi che $\sigma$ sia un run decisionale.
\end{itemize} 
\end{proof}
Abbiamo quindi tutti gli elementi per terminare la dimostrazione
iniziale, mostrando come si riesca a costruire un run ammissibile ma
non decisionale, ovvero una sequenza di passi che attraversa infinite
configurazioni solo bivalenti.

Grazie al Lemma \ref{lemma:bivalentInitialConfigurationExists}
sappiamo che esiste una configurazione iniziale bivalente, sia questa
$C_i$. Consideriamo un processore $p_{\alpha}$ e sia
$e_1^{\alpha},\ldots,e_j^{\alpha}$ una sequenza di eventi tali che
$C_i \xrightarrow{e_1^{\alpha}=(p_{\alpha},\perp)} C_1
\xrightarrow{e_2^{\alpha}=(p_{\alpha},\perp)} \ldots
\xrightarrow{e_{j-1}^{\alpha}=(p_{\alpha},\perp)} C_{j-1}
\xrightarrow{e_j^{\alpha}=(p_{\alpha},m)} D_{j}$. Osserviamo che le
configurazioni $C_1, \ldots, C_{j-1} \in \mathcal{C}$ rispetto
all'evento $e_j^{\alpha}=(p_{\alpha},m)$ e quindi, per il Lemma
\ref{lemma:oneStepFromConfigInCYieldConfigInD}, esiste $D_j \in
\mathcal{D}$ tale che $D_j$ \`e bivalente. Consideriamo adesso un
nuovo processore $p_{\beta}$ e costruiamo una sequenza di eventi
$e_1^{\beta},\ldots,e_k^{\beta}$ come fatto per il processore
$p_{\alpha}$ ed applichiamo tale sequenza alla configurazione $D_j$,
raggiungendo la configurazione $D_k$. Dato che $D_j$ \`e bivalente,
ancora per il Lemma \ref{lemma:oneStepFromConfigInCYieldConfigInD},
anche $D_k$ lo \`e. Ripetendo questo procedimento un numero arbitrario
di volte (la scelta di un processore $p_{\eta}$ \`e sempre possibile
in quanto esiste al pi\`u un processore guasto) usiamo le sequenze
construite per definire un run $\sigma$ composto dalla loro
concatenazione, ovvero $\sigma =
(e_1^{\alpha},\ldots,e_j^{\alpha},e_1^{\beta},\ldots,e_k^{\beta},\ldots)$. Il
run $\sigma$ \`e ammissibile ma non decisionale, contraddicendo
l'ipotesi di aver supposto il protocollo $P$ totalmente corretto a
meno di un guasto.
\end{proof}

\section{Protocollo di consenso in presenza di processori inizialmente guasti}

Il protocollo che ci accingiamo a presentare si occupa di risolvere il
problema del consenso supponendo di avere inizialmente la maggioranza
dei processori non guasti e nessun guasto durante l'esecuzione del
protocollo. Assumiamo che i processori non sappiano in anticipo quali
di loro sono guasti ma di lavorare in un sistema non uniforme dove il
numero $n$ dei processori presenti è noto, pertanto almeno
$L=\left\lceil\dfrac{n+1}{2}\right\rceil$ processori si assumono non
guasti. Il protocollo si articola in fasi.

\subsection{Prima fase}
In primo luogo ogni processore effettua un broadcast di un messaggio
contenente la propria \textsc{id} e attende di ricevere esattamente
$L-1$ messaggi, per collezionare $L-1$ \textsc{id} degli altri
processori, denoteremo con $\texttt{ancestors}(p)$ questo
insieme. Ricevuti tali messaggi, ogni processore costruisce un grafo
$G=(V,E)$ in cui $V$ contiene tutti gli $n$ processori mentre $E$
contiene l'arco $(i,j)$ se $j$ riceve un messaggio da $i$.

Illustriamo con un esempio questa prima fase. Consideriamo $n=8$ con
$2$ processori guasti e rappresentiamo in Figura (REF) i punti di
vista di $k,r$ e $j$. In particolare $k$ riceve messaggi da $\alpha,
\beta, \gamma$ ed $r$, $r$ riceve messaggi da $\alpha, \beta, \gamma$
e $j$, infine $j$ riceve messaggi da $\alpha, \beta, \gamma$ ed $r$.

\subsection{Seconda fase}
Ogni processore $p$ effettua un broadcast diffondendo il proprio
valore iniziale e l'insieme dei processori da cui ha ricevuto un
messaggio nella fase precedente. Questo secondo broadcast fa si che
ogni processore $p$ riceva informazioni sia dagli $L-1$ processori già
``conosciuti'' nella prima fase, sia dai restanti processori non
guasti, aggiornando il proprio grafo $G$ con le nuove informazioni.

Nel nostro esempio $k$ si aspetta di ricevere messaggi da $\alpha,
\beta, \gamma$ ed $r$ ma, per effetto del broadcast, riceverà un
messaggio anche da $j$. La sua conoscenza dopo aver collezionato
questi messaggi comprende
$\texttt{ancestors}(\alpha)\cup\texttt{ancestors}(\beta)\cup\texttt{ancestors}(\gamma)\cup\texttt{ancestors}(r)\cup\texttt{ancestors}(j)$.

\subsection{Terza fase}
Prima di descrivere la terza fase diamo un suggerimento su come
immaginarsi questo procedimento. Ogni processore $p$ ``disegna'' il
suo grafo usando colori diversi per rappresentare gli archi incidenti
ai processori ``conosciuti'' nella prima fase più quelli incedinti ai
processori ``conosciuti'' via broadcast nella seconda: per ogni
processore $q$ da cui $p$ ha ricevuto un messaggio, $p$ usa un colore
$c_q$, diverso dagli altri usati, per colorare gli archi incidenti a
$q$, ovvero per evidenziare l'insieme $\texttt{ancestors}(q)$.

Se adesso collezioniamo tutti i grafi disegnati e astraiamo dai
diversi colori usati dai processori, otterremo almeno $L$ copie dello
stesso grafo: possiamo quindi dedurre che almeno $L$ processori hanno
la stessa conoscenza.

Dato che tutti i processori hanno la stessa visione è possibile
chiudere transitivamente il grafo costruendo $G^+$; con questa
operazione si aggiungono eventuali self-loop e si trasformano i
cammini presenti in archi diretti.

\subsection{Quarta fase}
Per arrivare al consenso è necessario che $L$ processori decidano in
modo concorde; per raggiungere questo obiettivo usiamo il fatto che
hanno la stessa conoscenza per costruire una clique iniziale.
\begin{definizione}
  Considerando la chiusura transitiva $G^+$, un processore $p$
  appartiene a una clique iniziale se e solo se $\forall q:
  q\in\texttt{ancestors}(P)\rightarrow p\in\texttt{ancestors}(q)$.
\end{definizione} 
Ogni processore $p$ analizza ogni $q \in \texttt{ancestors(p)}$ e
determina se $q$ appartiene ad una clique iniziale. Dimostriamo alcune
proprietà delle clique così ottenute.


\begin{teorema}[Esistenza]
\label{teorema:esistenzaInitialClique}
  $G^+$ contiene almeno una clique iniziale.
\end{teorema}
\begin{proof}
  Sia $G^+$ la chiusura transitiva di $G$. In quanto tale, $G^+$
  contiene soltanto archi diretti: se due processori $\alpha$ e
  $\beta$ sono connessi in $G$ tramite un arco, allora anche in $G^+$
  sono connessi con un arco, altrimenti se $\alpha$ e $\beta$ sono
  connessi in $G$ tramite un cammino, allora in $G^+$ lo sono tramite
  un arco. Per definizione $p\in IC\leftrightarrow\forall q:
  q\in\texttt{ancestors}(p)\rightarrow p\in\texttt{ancestors}(q)$ e,
  equivalentemente, vale $p\not\in IC\leftrightarrow\exists q:
  q\in\texttt{ancestors}(p)\wedge p\not\in\texttt{ancestors}(q)$.

  Supponiamo per assurdo che $\forall p: p\not\in IC$: scegliamo
  arbitrariamente un processo $p$ e sia $q \in \texttt{ancestors}(p)$;
  poichè nessun processore $k \in G^+$ appartiene ad una clique
  iniziale allora $p \not \in \texttt{ancestors}(q)$. Essendo anche $q
  \in G^+$ possiamo ripetere lo stesso argomento per $q$, ovvero
  esisterà un processo $r \in \texttt{ancestors}(q)$ tale che $q \not
  \in \texttt{ancestors}(r)$. \'E utile osservare che $r$ non può
  essere proprio $p$, altrimenti $p \in \texttt{ancestors}(q)$, caso
  escluso precedentemente. Possiamo continuare a scegliere in modo
  arbitrario al più $n$ processori ma, una volta arrivati all'ultimo,
  sia questo $z$, dovremmo scegliere un processore $t \in
  \texttt{ancestors}(z)$, precedentemente considerato, tale che $z
  \not \in \texttt{ancestors}(t)$. Ma scegliendo $t$ si crea un ciclo,
  condizione sufficiente per introdurre un processore nella clique,
  contraddicendo l'ipotesi che $G^+$ non contiene clique
  iniziali
\end{proof}

\begin{teorema}[Estensione]
\label{teorema:estensioneInitialClique}
  Ogni clique iniziale ha almeno $L$ processori.
\end{teorema}
\begin{proof}
  Assumiamo per assurdo che esista una clique iniziale $IC$ tale che
  $|IC|\leq L-1$.  Consideriamo la prima fase del protocollo dove ogni
  processo non guasto riceve esattamente $L-1$ messaggi. Per il
  Teorema \ref{teorema:esistenzaInitialClique}, esiste almeno un
  processore non guasto $c \in IC$, il quale avrà ricevuto $L-1$
  messaggi avendo $L-1 = |\texttt{ancestors(c)}|$. Studiamo due casi
  \begin{itemize}
  \item se $\forall q \in \texttt{ancestors}(c) \rightarrow q \in IC$
    allora, essendoci al massimo $L-1$ processori nella clique
    iniziale, $c$ deve essere uno dei processori da cui ha ricevuto un
    messaggio. Ma questo è impossibile poichè nella prima fase nessun
    processore invia messaggi a se stesso;
  \item altrimenti deve esistere un processore $q \in
    \texttt{ancestors}(c)$, tale che $q \not \in IC$, quindi esiste un
    processore $r \in \texttt{ancestors} (q)$, tale che $q \not \in
    \texttt{ancestors} (r)$. Dato che stiamo lavorando su $G^+$,
    allora per transitivit\`a vale $r \in \texttt{ancestors} (c)$ e
    quindi, dato che per ipotesi $c \in IC$, segue che $r \in
    \texttt{ancestors} (c) \rightarrow c \in \texttt{ancestors}
    (r)$. Quest'ultima implicazione ci permette di arrivare ad una
    contraddizione in quanto, per transitivit\`a, si ha $q \in
    \texttt{ancestors}(r)$, caso escluso precedentemente.
  \end{itemize}
\end{proof}


\begin{teorema}[Unicità]
  \label{teorema:unicitaInitialClique}
  $G^+$ contiene non più di una clique iniziale.\end{teorema}
\begin{proof}
  Assumiamo che esistano due clique iniziali $IC_1, IC_2$ che, per il
  Teorema \ref{teorema:estensioneInitialClique}, hanno almeno $L$
  processori. Dato che $L>\dfrac{n}{2}$, le due clique hanno almeno un
  processore $p$ in comune. Per definizione di initial clique, $p$ è
  raggiungibile da tutti i processori di $IC_1$ e di $IC_2$ e,
  viceversa, tutti i processori delle due clique sono raggiungibili da
  $p$. Per transitività, tutti i processori di $IC_1$ possono
  raggiungere quelli di $IC_2$ passando per $p$ così come tutti i
  processori di $IC_2$ possono raggiungere quelli di $IC_1$ passando
  per $p$. In tal modo le due clique risultano fuse a formarne una
  unica, contraddicendo il fatto che $IC_1$ e $IC_2$ avevano solo $p$
  in comune.
\end{proof}

\begin{teorema}[Conoscenza]
\label{teorema:conoscenzaInitialClique}
  Ogni processore $p$, grazie a $G^+$, costruisce la stessa clique
  iniziale.
\end{teorema}
\begin{proof}
  Assumiamo per assurdo che esistano due processori $p$ e $q$ che
  costruiscono due clique iniziali $IC_p$ e $IC_q$ tali che $IC_p\neq
  IC_q$, differendo per almeno un processore $z$. Nel seguito
  assumiamo, senza perdita di generalità, che $p$ inserisca $z$ in
  $IC_q$ mentre $q$, erroneamente, non faccia lo stesso. Studiamo dal
  punto di vista di $q$: poichè $q$ ha deciso che $z$ non appartiene
  ad $IC_q$, deve esistere $\gamma \in \texttt{ancestors}(z)$ tale che
  $z \not \in \texttt{ancestors}(\gamma)$ (a torto) mentre, dal punto
  di vista di $p$, $z \in \texttt{ancestors}(\gamma)$ (a
  ragione). Distinguiamo due casi:
\begin{itemize}
\item se $q$ ha ricevuto un messaggio da $\gamma$ nella prima fase,
  allora $\gamma \in \texttt{ancestors}(q)$ e nella seconda fase, $q$
  riceverà da $\gamma$ l'informazione che $z \in
  \texttt{ancestors}(\gamma)$ (in quanto questo \`e il caso, per la
  ragione di $p$);
\item se $q$ non ha ricevuto alcun messaggio da $\gamma$ nella prima
  fase allora riceverà un messaggio di broadcast nella seconda,
  ricavando di nuovo che $z \in \texttt{ancestors}(\gamma)$.
\end{itemize} 
In entrambi i casi $q$ ottiene la conoscenza che $z \in
\texttt{ancestors}(\gamma)$, dunque anche $q$ avrebbe dovuto inserire
$z$ in $IC_q$, contraddicendo la sua scelta.
\end{proof}

\begin{teorema}[Correttezza]
  Il protocollo raggiunge il consenso se almeno $L$ processori sono
  non guasti e non si verificano guasti durante
  l'esecuzione.\end{teorema}
\begin{proof}
  Sia $G^+$ una chiusura transitiva di un grafo relativo al protocollo
  descritto: per il Teorema \ref{teorema:esistenzaInitialClique} e per
  il Teorema \ref{teorema:unicitaInitialClique}, in $G^+$ esiste un
  unica clique iniziale. Per il Teorema
  \ref{teorema:conoscenzaInitialClique}, ogni processore costruisce la
  stessa clique iniziale e questa ha almeno $L$ processori per il
  Teorema \ref{teorema:estensioneInitialClique}. Pertanto, dopo la
  seconda fase del protocollo, ogni processore conosce il valore
  iniziale di almeno la maggioranza dei processori ed, applicando una
  regola deterministica e stabilita a priori, \`e possibile
  raggiungere il consenso per i $L$ processori non guasti.
\end{proof}

\end{document}
